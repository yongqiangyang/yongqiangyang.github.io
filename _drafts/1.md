
1. 谷歌 机器学习 七步走！
2. 机器学习三兄弟：
3. npy：数据集
4. 数据集分法：811、82  
```
  import os  
  import glob  
  import numpy as np  
  from tensorflow.keras import layers  
  from tensorflow import keras  
  import tensorflow as tf

  def load_data(root, vfold_ratio=0.2, max_items_per_class= 4000 ):
    all_files = glob.glob(os.path.join(root, '*.npy'))

    #initialize variables
    x = np.empty([0, 784])
    y = np.empty([0])
    class_names = []
    #load each data file
    for idx, file in enumerate(all_files):
        data = np.load(file)
        data = data[0: max_items_per_class, :]
        labels = np.full(data.shape[0], idx)

        x = np.concatenate((x, data), axis=0)
        y = np.append(y, labels)

        class_name, ext = os.path.splitext(os.path.basename(file))
        class_names.append(class_name)

    data = None
    labels = None

    #randomize the dataset
    permutation = np.random.permutation(y.shape[0])
    x = x[permutation, :]
    y = y[permutation]

    #separate into training and testing
    vfold_size = int(x.shape[0]/100*(vfold_ratio*100))

    x_test = x[0:vfold_size, :]
    y_test = y[0:vfold_size]

    x_train = x[vfold_size:x.shape[0], :]
    y_train = y[vfold_size:y.shape[0]]
    return x_train, y_train, x_test, y_test, class_names
x_train, y_train, x_test, y_test, class_names = load_data('./data')
num_classes = len(class_names)
image_size = 28
import matplotlib.pyplot as plt
from random import randint
%matplotlib inline  
idx = randint(0, len(x_train))
plt.imshow(x_train[idx].reshape(28,28), cmap='gray')
plt.colorbar()
print(class_names[int(y_train[idx].item())])
# Reshape and normalize
x_train = x_train.reshape(x_train.shape[0], image_size, image_size, 1).astype('float32')
x_test = x_test.reshape(x_test.shape[0], image_size, image_size, 1).astype('float32')
x_train /= 255.0
x_test /= 255.0
# Convert class vectors to class matrices
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)
# Define model
model = keras.Sequential()
model.add(layers.Convolution2D(16, (3, 3),
                        padding='same',
                        input_shape=x_train.shape[1:], activation='relu', name="conv_1"))
model.add(layers.MaxPooling2D(pool_size=(2, 2), name="maxpool_1"))
model.add(layers.Convolution2D(32, (3, 3), padding='same', activation= 'relu', name="conv_2"))
model.add(layers.MaxPooling2D(pool_size=(2, 2), name="maxpool_2"))
model.add(layers.Convolution2D(64, (3, 3), padding='same', activation= 'relu', name="conv_3"))
model.add(layers.MaxPooling2D(pool_size =(2,2), name="maxpool_3"))
model.add(layers.Flatten())
model.add(layers.Dense(128, activation='relu', name="dense_1", kernel_regularizer=keras.regularizers.l2(0.001)))
model.add(keras.layers.Dropout(0.5))
model.add(layers.Dense(128, activation='relu', name="dense_2", kernel_regularizer=keras.regularizers.l2(0.001)))
model.add(keras.layers.Dropout(0.5))
model.add(layers.Dense(10, activation='softmax', name="dense_3"))
model.summary()
model.compile(optimizer=tf.train.AdamOptimizer(),
              loss='categorical_crossentropy',
              metrics=['accuracy'])
model.fit(x = x_train, y = y_train, validation_split=0.1, batch_size = 256, verbose=2, epochs=20, callbacks=[tensorboard_callback])
import matplotlib.pyplot as plt
from random import randint
%matplotlib inline  
idx = randint(0, len(x_test))
img = x_test[idx]
plt.imshow(img.squeeze(), cmap='gray')
pred = model.predict(np.expand_dims(img, axis=0))[0]
ind = (-pred).argsort()[:5]
latex = [class_names[x] for x in ind]
print(latex)
## 传入数据集中的 输入和输出
## 返回最总的loss值和准确率
test_loss, test_acc = model.evaluate(x_test, y_test)
print('Test accuracy:', test_acc)
```
